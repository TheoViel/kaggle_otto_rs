{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ["**About :** Computes Chris' matrices \n", "\n", "**TODO**:"],
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": ["/workspace/kaggle_otto_rs/src\n"],
                }
            ],
            "source": ["cd ../src"],
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": ["%load_ext autoreload\n", "%autoreload 2"],
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": ["%load_ext lab_black"],
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import gc\n",
                "import sys\n",
                "import cudf\n",
                "import json\n",
                "import glob\n",
                "import numba\n",
                "import pickle\n",
                "import warnings\n",
                "import itertools\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import multiprocessing\n",
                "\n",
                "from tqdm import tqdm\n",
                "from collections import defaultdict, Counter\n",
                "\n",
                'warnings.simplefilter(action="ignore", category=FutureWarning)\n',
                'cudf.set_option("default_integer_bitwidth", 32)\n',
                'cudf.set_option("default_float_bitwidth", 32)',
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": ["from params import *"],
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": ['MODE = "test"'],
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                'if MODE == "val":\n',
                '    files = glob.glob("../output/full_train_parquet/*") + glob.glob(\n',
                '        "../output/val_parquet/*"\n',
                "    )\n",
                'elif MODE == "test":\n',
                '    files = glob.glob("../output/full_train_val_parquet/*") + glob.glob(\n',
                '        "../output/test_parquet/*"\n',
                "    )\n",
                "else:\n",
                "    raise NotImplementedError",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": ['MATRIX_FOLDER = "../output/matrices/"'],
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[(0, 20),\n",
                            " (20, 40),\n",
                            " (40, 60),\n",
                            " (60, 80),\n",
                            " (80, 100),\n",
                            " (100, 120),\n",
                            " (120, 140),\n",
                            " (140, 146)]",
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result",
                }
            ],
            "source": [
                "CHUNK_SIZE = 20\n",
                "\n",
                "ids = np.arange(len(files) + 1, dtype=int)\n",
                "CHUNKS = [\n",
                "    (ids[c], ids[min(c + CHUNK_SIZE, len(ids) - 1)])\n",
                "    for c in range(0, len(files), CHUNK_SIZE)\n",
                "]\n",
                "\n",
                "CHUNKS",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_to_cache(files):\n",
                "    data_cache = {}\n",
                "    for file in tqdm(files):\n",
                "        df = pd.read_parquet(file)\n",
                '        df.ts = (df.ts / 1000).astype("int32")\n',
                '        df[["session", "aid"]] = df[["session", "aid"]].astype("int32")\n',
                '        df["type"] = df["type"].map(TYPE_LABELS).astype("int8")\n',
                "\n",
                "        data_cache[file] = df\n",
                "\n",
                "    return data_cache",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": ["# data_cache = load_to_cache(files)"],
        },
        {"cell_type": "markdown", "metadata": {}, "source": ["## gpu-93"]},
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pbar = tqdm(CHUNKS)\n",
                "for a, b in pbar:\n",
                '    pbar.set_description(f"Chunk [{a}, {b}]")\n',
                "    for k in range(a, b):\n",
                "        df = cudf.read_parquet(files[k])\n",
                '        df.ts = (df.ts / 1000).astype("int32")\n',
                '        df[["session", "aid"]] = df[["session", "aid"]].astype("int32")\n',
                '        df["type"] = df["type"].map(TYPE_LABELS).astype("int8")\n',
                "        gc.collect()\n",
                "        numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                '        df = df.sort_values(["session", "ts"], ascending=[True, False])\n',
                "        df = df.reset_index(drop=True)\n",
                '        df["n"] = df.groupby("session").cumcount()\n',
                '        df = df.loc[df.n < 30].drop("n", axis=1)\n',
                '        df = df.merge(df, on="session")\n',
                "        df = df.loc[((df.ts_x - df.ts_y).abs() < 24 * 60 * 60) & (df.aid_x != df.aid_y)]\n",
                '        df = df[["session", "aid_x", "aid_y", "ts_x", "ts_y"]].drop_duplicates(\n',
                '            ["session", "aid_x", "aid_y"]\n',
                "        )\n",
                '        df["wgt"] = 1 + 3 * (df.ts_x - 1659304800) / (1662328791 - 1659304800)\n',
                '        df["wgt"] = df["wgt"] * ((1 / 2) ** ((df.ts_x - df.ts_y).abs() / 60 / 60))\n',
                '        df = df[["aid_x", "aid_y", "wgt"]]\n',
                '        df.wgt = df.wgt.astype("float32")\n',
                '        df = df.groupby(["aid_x", "aid_y"]).wgt.sum()\n',
                "\n",
                "        if k == a:\n",
                "            tmp2 = df\n",
                "        else:\n",
                "            tmp2 = tmp2.add(df, fill_value=0)\n",
                "\n",
                "        del df\n",
                "        gc.collect()\n",
                "        numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                "    if a == 0:\n",
                "        tmp = tmp2\n",
                "    else:\n",
                "        tmp = tmp.add(tmp2, fill_value=0)\n",
                "\n",
                "    del tmp2\n",
                "    gc.collect()\n",
                "    numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tmp = tmp.reset_index()\n",
                'tmp = tmp.sort_values(["aid_x", "wgt"], ascending=[True, False])\n',
                "tmp = tmp.reset_index(drop=True)\n",
                'tmp["n"] = tmp.groupby("aid_x").aid_y.cumcount()\n',
                'tmp = tmp.loc[tmp.n < 80].drop("n", axis=1)',
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                'save_path = os.path.join(MATRIX_FOLDER, f"matrix_gpu-93_{MODE}.pqt")\n',
                'print(f"Saving matrix to {save_path}")\n',
                "tmp.to_pandas().to_parquet(save_path)",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "del tmp\n",
                "gc.collect()\n",
                "numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {"cell_type": "markdown", "metadata": {}, "source": ["### gpu-115"]},
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "type_weight = {0: 1, 1: 1, 2: 1}\n",
                "\n",
                "PIECES = 4\n",
                "SIZE = 1.86e6 / PIECES",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "matrices = []\n",
                "for PART in range(PIECES):\n",
                '    print("\\n- Part #", PART + 1)\n',
                "\n",
                "    # => OUTER CHUNKS\n",
                "    pbar = tqdm(CHUNKS)\n",
                "    for a, b in pbar:\n",
                '        pbar.set_description(f"Chunk [{a}, {b}]")\n',
                "\n",
                "        # => INNER CHUNKS\n",
                "        for k in range(a, b):\n",
                "            # READ FILE\n",
                "            df = cudf.read_parquet(files[k])\n",
                '            df.ts = (df.ts / 1000).astype("int32")\n',
                '            df[["session", "aid"]] = df[["session", "aid"]].astype("int32")\n',
                '            df["type"] = df["type"].map(TYPE_LABELS).astype("int8")\n',
                "            gc.collect()\n",
                "            numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                "            df = df.loc[df.ts > 1662328791 - 60 * 60 * 24 * 21]\n",
                "            if len(df) == 0:\n",
                "                continue\n",
                "\n",
                '            df = df.sort_values(["session", "ts"], ascending=[True, False])\n',
                "\n",
                "            # CREATE PAIRS\n",
                '            df = df.merge(df, on="session")\n',
                "\n",
                "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
                "            df = df.loc[(df.aid_x >= PART * SIZE) & (df.aid_x < (PART + 1) * SIZE)]\n",
                "\n",
                "            # ASSIGN WEIGHTS\n",
                "            df = df[\n",
                '                ["session", "aid_x", "aid_y", "type_y", "ts_y", "ts_x"]\n',
                '            ].drop_duplicates(["session", "aid_x", "aid_y"])\n',
                "            w = (1 / 2) ** ((df.ts_y - df.ts_x).abs() / 60 / 60)\n",
                '            df["wgt"] = df.type_y.map(type_weight) * w\n',
                '            df = df[["aid_x", "aid_y", "wgt"]]\n',
                "\n",
                '            df.wgt = df.wgt.astype("float32")\n',
                '            df = df.groupby(["aid_x", "aid_y"]).wgt.sum()\n',
                "\n",
                "            # COMBINE INNER CHUNKS\n",
                "            if k == a:\n",
                "                tmp2 = df\n",
                "            else:\n",
                "                tmp2 = tmp2.add(df, fill_value=0)\n",
                "\n",
                "            del df\n",
                "            gc.collect()\n",
                "            numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                "        # COMBINE OUTER CHUNKS\n",
                "        if a == 0:\n",
                "            tmp = tmp2\n",
                "        else:\n",
                "            tmp = tmp.add(tmp2, fill_value=0)\n",
                "        del tmp2\n",
                "        gc.collect()\n",
                "        numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                "    # CONVERT MATRIX TO DICTIONARY\n",
                "    tmp = tmp.reset_index()\n",
                '    tmp = tmp.sort_values(["aid_x", "wgt"], ascending=[True, False])\n',
                "\n",
                "    # SAVE TOP\n",
                "    tmp = tmp.reset_index(drop=True)\n",
                '    tmp["n"] = tmp.groupby("aid_x").aid_y.cumcount()\n',
                '    tmp = tmp.loc[tmp.n < 40].drop("n", axis=1)\n',
                "    matrices.append(tmp.to_pandas())\n",
                "\n",
                "    del tmp\n",
                "    gc.collect()\n",
                "    numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                'save_path = os.path.join(MATRIX_FOLDER, f"matrix_gpu-115_{MODE}.pqt")\n',
                'print(f"Saving matrix to {save_path}")\n',
                "pd.concat(matrices, ignore_index=True).to_parquet(save_path)\n",
                "\n",
                "del matrices\n",
                "gc.collect()\n",
                "numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {"cell_type": "markdown", "metadata": {}, "source": ["### gpu-116"]},
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "type_weight = {0: 0, 1: 1, 2: 1}\n",
                "\n",
                "PIECES = 4\n",
                "SIZE = 1.86e6 / PIECES",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "matrices = []\n",
                "for PART in range(PIECES):\n",
                '    print("\\n- Part #", PART + 1)\n',
                "\n",
                "    # => OUTER CHUNKS\n",
                "    pbar = tqdm(CHUNKS)\n",
                "    for a, b in pbar:\n",
                '        pbar.set_description(f"Chunk [{a}, {b}]")\n',
                "\n",
                "        # => INNER CHUNKS\n",
                "        for k in range(a, b):\n",
                "            # READ FILE\n",
                "            df = cudf.read_parquet(files[k])\n",
                '            df.ts = (df.ts / 1000).astype("int32")\n',
                '            df[["session", "aid"]] = df[["session", "aid"]].astype("int32")\n',
                '            df["type"] = df["type"].map(TYPE_LABELS).astype("int8")\n',
                "            gc.collect()\n",
                "            numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                "            df = df.loc[df.ts > 1662328791 - 60 * 60 * 24 * 28]\n",
                "            if len(df) == 0:\n",
                "                continue\n",
                "\n",
                '            df = df.sort_values(["session", "ts"], ascending=[True, False])\n',
                "\n",
                "            # CREATE PAIRS\n",
                '            df = df.merge(df, on="session")\n',
                "            df = df.loc[(df.ts_y - df.ts_x) > 0]\n",
                "\n",
                "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
                "            df = df.loc[(df.aid_x >= PART * SIZE) & (df.aid_x < (PART + 1) * SIZE)]\n",
                "\n",
                "            # ASSIGN WEIGHTS\n",
                "            df = df[\n",
                '                ["session", "aid_x", "aid_y", "type_y", "ts_y", "ts_x"]\n',
                '            ].drop_duplicates(["session", "aid_x", "aid_y"])\n',
                "            w = (1 / 2) ** ((df.ts_y - df.ts_x) / 60 / 60)\n",
                '            df["wgt"] = df.type_y.map(type_weight) * w\n',
                "\n",
                '            df = df[["aid_x", "aid_y", "wgt"]]\n',
                "\n",
                '            df.wgt = df.wgt.astype("float32")\n',
                '            df = df.groupby(["aid_x", "aid_y"]).wgt.sum()\n',
                "\n",
                "            # COMBINE INNER CHUNKS\n",
                "            if k == a:\n",
                "                tmp2 = df\n",
                "            else:\n",
                "                tmp2 = tmp2.add(df, fill_value=0)\n",
                "\n",
                "            del df\n",
                "            gc.collect()\n",
                "            numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                "        # COMBINE OUTER CHUNKS\n",
                "        if a == 0:\n",
                "            tmp = tmp2\n",
                "        else:\n",
                "            tmp = tmp.add(tmp2, fill_value=0)\n",
                "\n",
                "        del tmp2\n",
                "        gc.collect()\n",
                "        numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                "    # CONVERT MATRIX TO DICTIONARY\n",
                "    tmp = tmp.reset_index()\n",
                '    tmp = tmp.sort_values(["aid_x", "wgt"], ascending=[True, False])\n',
                "\n",
                "    # SAVE TOP\n",
                "    tmp = tmp.reset_index(drop=True)\n",
                '    tmp["n"] = tmp.groupby("aid_x").aid_y.cumcount()\n',
                '    tmp = tmp.loc[tmp.n < 40].drop("n", axis=1)\n',
                "    matrices.append(tmp.to_pandas())\n",
                "\n",
                "    del tmp\n",
                "    gc.collect()\n",
                "    numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                'save_path = os.path.join(MATRIX_FOLDER, f"matrix_gpu-116_{MODE}.pqt")\n',
                'print(f"Saving matrix to {save_path}")\n',
                "pd.concat(matrices, ignore_index=True).to_parquet(save_path)\n",
                "\n",
                "del matrices\n",
                "gc.collect()\n",
                "numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {"cell_type": "markdown", "metadata": {}, "source": ["### gpu-217"]},
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ["PIECES = 1\n", "SIZE = 1.86e6 / PIECES"],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "matrices = []\n",
                "for PART in range(PIECES):\n",
                '    print("\\n- Part #", PART + 1)\n',
                "\n",
                "    # => OUTER CHUNKS\n",
                "    pbar = tqdm(CHUNKS)\n",
                "    for a, b in pbar:\n",
                '        pbar.set_description(f"Chunk [{a}, {b}]")\n',
                "\n",
                "        # => INNER CHUNKS\n",
                "        for k in range(a, b):\n",
                "            # READ FILE\n",
                "            df = cudf.read_parquet(files[k])\n",
                '            df.ts = (df.ts / 1000).astype("int32")\n',
                '            df[["session", "aid"]] = df[["session", "aid"]].astype("int32")\n',
                '            df["type"] = df["type"].map(TYPE_LABELS).astype("int8")\n',
                "            gc.collect()\n",
                "            numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                '            df = df.sort_values(["session", "ts"], ascending=[True, True])\n',
                '            df["k"] = np.arange(len(df))\n',
                "            # USE TAIL OF SESSION\n",
                "            # df = df.reset_index(drop=True)\n",
                "            # df['n'] = df.groupby('session').cumcount()\n",
                "            # df = df.loc[df.n<100].drop('n',axis=1)\n",
                "            # CREATE PAIRS\n",
                '            df = df.merge(df.drop_duplicates(["session", "aid"]), on=["session"])\n',
                "            df = df.loc[((df.k_y - df.k_x).abs() == 1) & (df.aid_x != df.aid_y)]\n",
                "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
                "            df = df.loc[(df.aid_x >= PART * SIZE) & (df.aid_x < (PART + 1) * SIZE)]\n",
                "            # df = df.sort_values('ts_x',ascending=False)\n",
                "            # ASSIGN WEIGHTS\n",
                '            df = df[["session", "aid_x", "aid_y"]].drop_duplicates(\n',
                '                ["session", "aid_x", "aid_y"]\n',
                "            )\n",
                '            df["wgt"] = 1\n',
                "\n",
                '            df = df[["aid_x", "aid_y", "wgt"]]\n',
                '            df.wgt = df.wgt.astype("float32")\n',
                '            df = df.groupby(["aid_x", "aid_y"]).wgt.sum()\n',
                "            # COMBINE INNER CHUNKS\n",
                "            if k == a:\n",
                "                tmp2 = df\n",
                "            else:\n",
                "                tmp2 = tmp2.add(df, fill_value=0)\n",
                "\n",
                "            del df\n",
                "            gc.collect()\n",
                "            numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                "        # COMBINE OUTER CHUNKS\n",
                "        if a == 0:\n",
                "            tmp = tmp2\n",
                "        else:\n",
                "            tmp = tmp.add(tmp2, fill_value=0)\n",
                "\n",
                "        del tmp2\n",
                "        gc.collect()\n",
                "        numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                "    # CONVERT MATRIX TO DICTIONARY\n",
                "    tmp = tmp.reset_index()\n",
                '    tmp = tmp.sort_values(["aid_x", "wgt"], ascending=[True, False])\n',
                "\n",
                "    # SAVE TOP 40\n",
                "    tmp = tmp.reset_index(drop=True)\n",
                '    tmp["n"] = tmp.groupby("aid_x").aid_y.cumcount()\n',
                '    tmp = tmp.loc[tmp.n < 40].drop("n", axis=1)\n',
                "    matrices.append(tmp.to_pandas())\n",
                "\n",
                "    del tmp\n",
                "    gc.collect()\n",
                "    numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                'save_path = os.path.join(MATRIX_FOLDER, f"matrix_gpu-217_{MODE}.pqt")\n',
                'print(f"Saving matrix to {save_path}")\n',
                "pd.concat(matrices, ignore_index=True).to_parquet(save_path)\n",
                "\n",
                "del matrices\n",
                "gc.collect()\n",
                "numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {"cell_type": "markdown", "metadata": {}, "source": ["### gpu-220"]},
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ["PIECES = 1\n", "SIZE = 1.86e6 / PIECES"],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "matrices = []\n",
                "for PART in range(PIECES):\n",
                '    print("\\n- Part #", PART + 1)\n',
                "\n",
                "    # => OUTER CHUNKS\n",
                "    pbar = tqdm(CHUNKS)\n",
                "    for a, b in pbar:\n",
                '        pbar.set_description(f"Chunk [{a}, {b}]")\n',
                "\n",
                "        # => INNER CHUNKS\n",
                "        for k in range(a, b):\n",
                "            # READ FILE\n",
                "            df = cudf.read_parquet(files[k])\n",
                '            df.ts = (df.ts / 1000).astype("int32")\n',
                '            df[["session", "aid"]] = df[["session", "aid"]].astype("int32")\n',
                '            df["type"] = df["type"].map(TYPE_LABELS).astype("int8")\n',
                "            gc.collect()\n",
                "            numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                '            df = df.sort_values(["session", "ts"], ascending=[True, True])\n',
                '            df["k"] = np.arange(len(df))\n',
                "\n",
                "            # CREATE PAIRS\n",
                '            df = df.merge(df.drop_duplicates(["session", "aid"]), on=["session"])\n',
                "            df = df.loc[\n",
                "                ((df.k_y - df.k_x).abs() >= 1)\n",
                "                & ((df.k_y - df.k_x).abs() <= 2)\n",
                "                & (df.aid_x != df.aid_y)\n",
                "            ]\n",
                "\n",
                "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
                "            df = df.loc[(df.aid_x >= PART * SIZE) & (df.aid_x < (PART + 1) * SIZE)]\n",
                "\n",
                "            # ASSIGN WEIGHTS\n",
                '            df = df[["session", "aid_x", "aid_y"]].drop_duplicates(\n',
                '                ["session", "aid_x", "aid_y"]\n',
                "            )\n",
                '            df["wgt"] = 1\n',
                "\n",
                '            df = df[["aid_x", "aid_y", "wgt"]]\n',
                '            df.wgt = df.wgt.astype("float32")\n',
                '            df = df.groupby(["aid_x", "aid_y"]).wgt.sum()\n',
                "\n",
                "            # COMBINE INNER CHUNKS\n",
                "            if k == a:\n",
                "                tmp2 = df\n",
                "            else:\n",
                "                tmp2 = tmp2.add(df, fill_value=0)\n",
                "\n",
                "            del df\n",
                "            gc.collect()\n",
                "            numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                "        # COMBINE OUTER CHUNKS\n",
                "        if a == 0:\n",
                "            tmp = tmp2\n",
                "        else:\n",
                "            tmp = tmp.add(tmp2, fill_value=0)\n",
                "\n",
                "        del tmp2\n",
                "        gc.collect()\n",
                "        numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                "    # CONVERT MATRIX TO DICTIONARY\n",
                "    tmp = tmp.reset_index()\n",
                '    tmp = tmp.sort_values(["aid_x", "wgt"], ascending=[True, False])\n',
                "\n",
                "    # SAVE TOP\n",
                "    tmp = tmp.reset_index(drop=True)\n",
                '    tmp["n"] = tmp.groupby("aid_x").aid_y.cumcount()\n',
                '    tmp = tmp.loc[tmp.n < 80].drop("n", axis=1)\n',
                "    matrices.append(tmp.to_pandas())\n",
                "\n",
                "    del tmp\n",
                "    gc.collect()\n",
                "    numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                'save_path = os.path.join(MATRIX_FOLDER, f"matrix_gpu-220_{MODE}.pqt")\n',
                'print(f"Saving matrix to {save_path}")\n',
                "pd.concat(matrices, ignore_index=True).to_parquet(save_path)\n",
                "\n",
                "del matrices\n",
                "gc.collect()\n",
                "numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {"cell_type": "markdown", "metadata": {}, "source": ["### gpu-226"]},
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ["PIECES = 1\n", "SIZE = 1.86e6 / PIECES"],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "matrices = []\n",
                "for PART in range(PIECES):\n",
                '    print("\\n- Part #", PART + 1)\n',
                "\n",
                "    # => OUTER CHUNKS\n",
                "    pbar = tqdm(CHUNKS)\n",
                "    for a, b in pbar:\n",
                '        pbar.set_description(f"Chunk [{a}, {b}]")\n',
                "\n",
                "        # => INNER CHUNKS\n",
                "        for k in range(a, b):\n",
                "            # READ FILE\n",
                "            df = cudf.read_parquet(files[k])\n",
                '            df.ts = (df.ts / 1000).astype("int32")\n',
                '            df[["session", "aid"]] = df[["session", "aid"]].astype("int32")\n',
                '            df["type"] = df["type"].map(TYPE_LABELS).astype("int8")\n',
                "            gc.collect()\n",
                "            numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                '            df = df.loc[df["type"].isin([1, 2])]\n',
                "\n",
                '            df = df.sort_values(["session", "ts"], ascending=[True, True])\n',
                '            df["k"] = np.arange(len(df))\n',
                "\n",
                "            # CREATE PAIRS\n",
                '            df = df.merge(df.drop_duplicates(["session", "aid"]), on=["session"])\n',
                "            df = df.loc[\n",
                "                ((df.k_y - df.k_x) >= 1)\n",
                "                & ((df.k_y - df.k_x) <= 3)\n",
                "                & (df.aid_x != df.aid_y)\n",
                "            ]\n",
                "\n",
                "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
                "            df = df.loc[(df.aid_x >= PART * SIZE) & (df.aid_x < (PART + 1) * SIZE)]\n",
                "\n",
                "            # ASSIGN WEIGHTS\n",
                '            df = df[["session", "aid_x", "aid_y"]].drop_duplicates(\n',
                '                ["session", "aid_x", "aid_y"]\n',
                "            )\n",
                '            df["wgt"] = 1\n',
                "\n",
                '            df = df[["aid_x", "aid_y", "wgt"]]\n',
                '            df.wgt = df.wgt.astype("float32")\n',
                '            df = df.groupby(["aid_x", "aid_y"]).wgt.sum()\n',
                "\n",
                "            # COMBINE INNER CHUNKS\n",
                "            if k == a:\n",
                "                tmp2 = df\n",
                "            else:\n",
                "                tmp2 = tmp2.add(df, fill_value=0)\n",
                "\n",
                "            del df\n",
                "            gc.collect()\n",
                "            numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                "        # COMBINE OUTER CHUNKS\n",
                "        if a == 0:\n",
                "            tmp = tmp2\n",
                "        else:\n",
                "            tmp = tmp.add(tmp2, fill_value=0)\n",
                "        del tmp2\n",
                "        gc.collect()\n",
                "        numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                "    # CONVERT MATRIX TO DICTIONARY\n",
                "    tmp = tmp.reset_index()\n",
                '    tmp = tmp.sort_values(["aid_x", "wgt"], ascending=[True, False])\n',
                "\n",
                "    # SAVE TOP\n",
                "    tmp = tmp.reset_index(drop=True)\n",
                '    tmp["n"] = tmp.groupby("aid_x").aid_y.cumcount()\n',
                '    tmp = tmp.loc[tmp.n < 80].drop("n", axis=1)\n',
                "    matrices.append(tmp.to_pandas())\n",
                "\n",
                "    del tmp\n",
                "    gc.collect()\n",
                "    numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                'save_path = os.path.join(MATRIX_FOLDER, f"matrix_gpu-226_{MODE}.pqt")\n',
                'print(f"Saving matrix to {save_path}")\n',
                "pd.concat(matrices, ignore_index=True).to_parquet(save_path)\n",
                "\n",
                "del matrices\n",
                "gc.collect()\n",
                "numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {"cell_type": "markdown", "metadata": {}, "source": ["### gpu-232"]},
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "type_weight = {0: 1, 1: 1, 2: 1}\n",
                "\n",
                "PIECES = 1\n",
                "SIZE = 1.86e6 / PIECES",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "matrices = []\n",
                "for PART in range(PIECES):\n",
                '    print("\\n- Part #", PART + 1)\n',
                "\n",
                "    # => OUTER CHUNKS\n",
                "    pbar = tqdm(CHUNKS)\n",
                "    for a, b in pbar:\n",
                '        pbar.set_description(f"Chunk [{a}, {b}]")\n',
                "\n",
                "        # => INNER CHUNKS\n",
                "        for k in range(a, b):\n",
                "            # READ FILE\n",
                "            df = cudf.read_parquet(files[k])\n",
                '            df.ts = (df.ts / 1000).astype("int32")\n',
                '            df[["session", "aid"]] = df[["session", "aid"]].astype("int32")\n',
                '            df["type"] = df["type"].map(TYPE_LABELS).astype("int8")\n',
                "            gc.collect()\n",
                "            numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                '            df = df.sort_values(["session", "ts"], ascending=[True, True])\n',
                '            df["k"] = np.arange(len(df))\n',
                "\n",
                "            # CREATE PAIRS\n",
                '            df = df.merge(df.drop_duplicates(["session", "aid"]), on=["session"])\n',
                "            df = df.loc[\n",
                "                ((df.k_y - df.k_x).abs() >= 1)\n",
                "                & ((df.k_y - df.k_x).abs() <= 3)\n",
                "                & (df.aid_x != df.aid_y)\n",
                "            ]\n",
                "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
                "            df = df.loc[(df.aid_x >= PART * SIZE) & (df.aid_x < (PART + 1) * SIZE)]\n",
                "\n",
                "            # ASSIGN WEIGHTS\n",
                '            df = df[["session", "aid_x", "aid_y", "ts_x", "ts_y"]].drop_duplicates(\n',
                '                ["session", "aid_x", "aid_y"]\n',
                "            )\n",
                "            w = (1 / 2) ** ((df.ts_x - df.ts_y).abs() / 60 / 60)\n",
                '            df["wgt"] = w  # df.type_y.map(type_weight)\n',
                "\n",
                '            df = df[["aid_x", "aid_y", "wgt"]]\n',
                '            df.wgt = df.wgt.astype("float32")\n',
                '            df = df.groupby(["aid_x", "aid_y"]).wgt.sum()\n',
                "\n",
                "            # COMBINE INNER CHUNKS\n",
                "            if k == a:\n",
                "                tmp2 = df\n",
                "            else:\n",
                "                tmp2 = tmp2.add(df, fill_value=0)\n",
                "\n",
                "        # COMBINE OUTER CHUNKS\n",
                "        if a == 0:\n",
                "            tmp = tmp2\n",
                "        else:\n",
                "            tmp = tmp.add(tmp2, fill_value=0)\n",
                "        del tmp2, df\n",
                "        gc.collect()\n",
                "        numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                "    # CONVERT MATRIX TO DICTIONARY\n",
                "    tmp = tmp.reset_index()\n",
                '    tmp = tmp.sort_values(["aid_x", "wgt"], ascending=[True, False])\n',
                "\n",
                "    # SAVE TOP\n",
                "    tmp = tmp.reset_index(drop=True)\n",
                '    tmp["n"] = tmp.groupby("aid_x").aid_y.cumcount()\n',
                '    tmp = tmp.loc[tmp.n < 80].drop("n", axis=1)\n',
                "    matrices.append(tmp.to_pandas())\n",
                "\n",
                "    del tmp\n",
                "    gc.collect()\n",
                "    numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                'save_path = os.path.join(MATRIX_FOLDER, f"matrix_gpu-232_{MODE}.pqt")\n',
                'print(f"Saving matrix to {save_path}")\n',
                "pd.concat(matrices, ignore_index=True).to_parquet(save_path)\n",
                "\n",
                "del matrices\n",
                "gc.collect()\n",
                "numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {"cell_type": "markdown", "metadata": {}, "source": ["### gpu-235"]},
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "type_weight = {0: 1, 1: 1, 2: 1}\n",
                "\n",
                "PIECES = 3\n",
                "SIZE = 1.86e6 / PIECES",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "matrices = []\n",
                "for PART in range(PIECES):\n",
                '    print("\\n- Part #", PART + 1)\n',
                "\n",
                "    # => OUTER CHUNKS\n",
                "    pbar = tqdm(CHUNKS)\n",
                "    for a, b in pbar:\n",
                '        pbar.set_description(f"Chunk [{a}, {b}]")\n',
                "\n",
                "        # => INNER CHUNKS\n",
                "        for k in range(a, b):\n",
                "            # READ FILE\n",
                "            df = cudf.read_parquet(files[k])\n",
                '            df.ts = (df.ts / 1000).astype("int32")\n',
                '            df[["session", "aid"]] = df[["session", "aid"]].astype("int32")\n',
                '            df["type"] = df["type"].map(TYPE_LABELS).astype("int8")\n',
                "            gc.collect()\n",
                "            numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                '            df = df.sort_values(["session", "ts"], ascending=[True, True])\n',
                '            df["k"] = np.arange(len(df))\n',
                "\n",
                "            # CREATE PAIRS\n",
                '            df = df.merge(df.drop_duplicates(["session", "aid"]), on=["session"])\n',
                "            df = df.loc[\n",
                "                ((df.k_y - df.k_x).abs() >= 1)\n",
                "                & ((df.k_y - df.k_x).abs() <= 6)\n",
                "                & (df.aid_x != df.aid_y)\n",
                "            ]\n",
                "\n",
                "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
                "            df = df.loc[(df.aid_x >= PART * SIZE) & (df.aid_x < (PART + 1) * SIZE)]\n",
                "\n",
                "            # ASSIGN WEIGHTS\n",
                '            df = df[["session", "aid_x", "aid_y", "ts_x", "ts_y"]].drop_duplicates(\n',
                '                ["session", "aid_x", "aid_y"]\n',
                "            )\n",
                "            w = (1 / 2) ** ((df.ts_x - df.ts_y).abs() / 60 / 60)\n",
                '            df["wgt"] = w\n',
                "\n",
                '            df = df[["aid_x", "aid_y", "wgt"]]\n',
                '            df.wgt = df.wgt.astype("float32")\n',
                '            df = df.groupby(["aid_x", "aid_y"]).wgt.sum()\n',
                "            # COMBINE INNER CHUNKS\n",
                "            if k == a:\n",
                "                tmp2 = df\n",
                "            else:\n",
                "                tmp2 = tmp2.add(df, fill_value=0)\n",
                "\n",
                "        # COMBINE OUTER CHUNKS\n",
                "        if a == 0:\n",
                "            tmp = tmp2\n",
                "        else:\n",
                "            tmp = tmp.add(tmp2, fill_value=0)\n",
                "        del tmp2, df\n",
                "        gc.collect()\n",
                "\n",
                "    # CONVERT MATRIX TO DICTIONARY\n",
                "    tmp = tmp.reset_index()\n",
                '    tmp = tmp.sort_values(["aid_x", "wgt"], ascending=[True, False])\n',
                "\n",
                "    # SAVE TOP\n",
                "    tmp = tmp.reset_index(drop=True)\n",
                '    tmp["n"] = tmp.groupby("aid_x").aid_y.cumcount()\n',
                '    tmp = tmp.loc[tmp.n < 80].drop("n", axis=1)\n',
                "    matrices.append(tmp.to_pandas())\n",
                "\n",
                "    del tmp\n",
                "    gc.collect()\n",
                "    numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                'save_path = os.path.join(MATRIX_FOLDER, f"matrix_gpu-235_{MODE}.pqt")\n',
                'print(f"Saving matrix to {save_path}")\n',
                "pd.concat(matrices, ignore_index=True).to_parquet(save_path)\n",
                "\n",
                "del matrices\n",
                "gc.collect()\n",
                "numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {"cell_type": "markdown", "metadata": {}, "source": ["### gpu-239"]},
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "type_weight = {0: 1, 1: 1, 2: 1}\n",
                "\n",
                "PIECES = 1\n",
                "SIZE = 1.86e6 / PIECES",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "matrices = []\n",
                "for PART in range(PIECES):\n",
                '    print("\\n- Part #", PART + 1)\n',
                "\n",
                "    # => OUTER CHUNKS\n",
                "    pbar = tqdm(CHUNKS)\n",
                "    for a, b in pbar:\n",
                '        pbar.set_description(f"Chunk [{a}, {b}]")\n',
                "\n",
                "        # => INNER CHUNKS\n",
                "        for k in range(a, b):\n",
                "            # READ FILE\n",
                "            df = cudf.read_parquet(files[k])\n",
                '            df.ts = (df.ts / 1000).astype("int32")\n',
                '            df[["session", "aid"]] = df[["session", "aid"]].astype("int32")\n',
                '            df["type"] = df["type"].map(TYPE_LABELS).astype("int8")\n',
                "            gc.collect()\n",
                "            numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                "            # CREATE PAIRS\n",
                '            df = df.merge(df.loc[df["type"].isin([1, 2])], on=["session"])\n',
                "            df = df.loc[(df.ts_y - df.ts_x > 0) & (df.ts_y - df.ts_x < 60 * 60 * 2)]\n",
                "\n",
                '            df["d"] = df.ts_y - df.ts_x\n',
                '            df = df.sort_values(["d"], ascending=[True])\n',
                '            df = df.drop_duplicates(["aid_x", "aid_y"]).drop("d", axis=1)\n',
                "\n",
                "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
                "            df = df.loc[(df.aid_x >= PART * SIZE) & (df.aid_x < (PART + 1) * SIZE)]\n",
                "\n",
                "            # ASSIGN WEIGHTS\n",
                '            df["wgt"] = (1 / 2) ** ((df.ts_y - df.ts_x) / 60 / 60)\n',
                "\n",
                '            df = df[["aid_x", "aid_y", "wgt"]]\n',
                '            df.wgt = df.wgt.astype("float32")\n',
                '            df = df.groupby(["aid_x", "aid_y"]).wgt.sum()\n',
                "\n",
                "            # COMBINE INNER CHUNKS\n",
                "            if k == a:\n",
                "                tmp2 = df\n",
                "            else:\n",
                "                tmp2 = tmp2.add(df, fill_value=0)\n",
                "\n",
                "        # COMBINE OUTER CHUNKS\n",
                "        if a == 0:\n",
                "            tmp = tmp2\n",
                "        else:\n",
                "            tmp = tmp.add(tmp2, fill_value=0)\n",
                "        del tmp2, df\n",
                "        gc.collect()\n",
                "\n",
                "    # CONVERT MATRIX TO DICTIONARY\n",
                "    tmp = tmp.reset_index()\n",
                '    tmp = tmp.sort_values(["aid_x", "wgt"], ascending=[True, False])\n',
                "\n",
                "    # SAVE TOP\n",
                "    tmp = tmp.reset_index(drop=True)\n",
                '    tmp["n"] = tmp.groupby("aid_x").aid_y.cumcount()\n',
                '    tmp = tmp.loc[tmp.n < 20].drop("n", axis=1)\n',
                "    matrices.append(tmp.to_pandas())\n",
                "\n",
                "    del tmp\n",
                "    gc.collect()\n",
                "    numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                'save_path = os.path.join(MATRIX_FOLDER, f"matrix_gpu-239_{MODE}.pqt")\n',
                'print(f"Saving matrix to {save_path}")\n',
                "pd.concat(matrices, ignore_index=True).to_parquet(save_path)\n",
                "\n",
                "del matrices\n",
                "gc.collect()\n",
                "numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {"cell_type": "markdown", "metadata": {}, "source": ["### gpu-700"]},
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ["PIECES = 1\n", "SIZE = 1.86e6 / PIECES"],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "matrices = []\n",
                "for PART in range(PIECES):\n",
                '    print("\\n- Part #", PART + 1)\n',
                "\n",
                "    # => OUTER CHUNKS\n",
                "    pbar = tqdm(CHUNKS)\n",
                "    for a, b in pbar:\n",
                '        pbar.set_description(f"Chunk [{a}, {b}]")\n',
                "\n",
                "        # => INNER CHUNKS\n",
                "        for k in range(a, b):\n",
                "            # READ FILE\n",
                "            df = cudf.read_parquet(files[k])\n",
                '            df.ts = (df.ts / 1000).astype("int32")\n',
                '            df[["session", "aid"]] = df[["session", "aid"]].astype("int32")\n',
                '            df["type"] = df["type"].map(TYPE_LABELS).astype("int8")\n',
                "            gc.collect()\n",
                "            numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                "            # NEW USERS IN LAST 2 WEEKS\n",
                '            df["mn"] = df.groupby("session").ts.transform("min")\n',
                "            df = df.loc[df.mn > 1662328791 - 60 * 60 * 24 * 21]\n",
                '            df = df.drop("mn", axis=1)\n',
                "\n",
                '            df = df.sort_values(["session", "ts"], ascending=[True, True])\n',
                "\n",
                "            # USE TAIL OF SESSION\n",
                "            df = df.reset_index(drop=True)\n",
                '            df["n"] = df.groupby("session").cumcount()\n',
                "\n",
                "            # CREATE PAIRS\n",
                '            df = df.loc[df.n == 0].merge(df.loc[df["type"] > 0], on=["session"])\n',
                "            df = df.loc[df.aid_x != df.aid_y]\n",
                "\n",
                "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
                "            df = df.loc[(df.aid_x >= PART * SIZE) & (df.aid_x < (PART + 1) * SIZE)]\n",
                "\n",
                "            # ASSIGN WEIGHTS\n",
                '            df = df.sort_values(["session", "ts_y"], ascending=[True, True])\n',
                '            df = df[["session", "aid_x", "aid_y", "type_y"]].drop_duplicates(\n',
                '                ["session", "aid_x", "aid_y", "type_y"]\n',
                "            )\n",
                '            df["wgt"] = 1\n',
                "\n",
                '            df = df[["aid_x", "aid_y", "wgt"]]\n',
                '            df.wgt = df.wgt.astype("float32")\n',
                '            df = df.groupby(["aid_x", "aid_y"]).wgt.sum()\n',
                "\n",
                "            # COMBINE INNER CHUNKS\n",
                "            if k == a:\n",
                "                tmp2 = df\n",
                "            else:\n",
                "                tmp2 = tmp2.add(df, fill_value=0)\n",
                "\n",
                "        # COMBINE OUTER CHUNKS\n",
                "        if a == 0:\n",
                "            tmp = tmp2\n",
                "        else:\n",
                "            tmp = tmp.add(tmp2, fill_value=0)\n",
                "        del tmp2, df\n",
                "        gc.collect()\n",
                "\n",
                "    # CONVERT MATRIX TO DICTIONARY\n",
                "    tmp = tmp.reset_index()\n",
                '    tmp = tmp.sort_values(["aid_x", "wgt"], ascending=[True, False])\n',
                "\n",
                "    # SAVE TOP\n",
                "    tmp = tmp.reset_index(drop=True)\n",
                '    tmp["n"] = tmp.groupby("aid_x").aid_y.cumcount()\n',
                '    tmp = tmp.loc[tmp.n < 40].drop("n", axis=1)\n',
                "    matrices.append(tmp.to_pandas())\n",
                "\n",
                "    del tmp\n",
                "    gc.collect()\n",
                "    numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                'save_path = os.path.join(MATRIX_FOLDER, f"matrix_gpu-700_{MODE}.pqt")\n',
                'print(f"Saving matrix to {save_path}")\n',
                "pd.concat(matrices, ignore_index=True).to_parquet(save_path)\n",
                "\n",
                "del matrices\n",
                "gc.collect()\n",
                "numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {"cell_type": "markdown", "metadata": {}, "source": ["### gpu-701"]},
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ["PIECES = 1\n", "SIZE = 1.86e6 / PIECES"],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "matrices = []\n",
                "for PART in range(PIECES):\n",
                '    print("\\n- Part #", PART + 1)\n',
                "\n",
                "    # => OUTER CHUNKS\n",
                "    pbar = tqdm(CHUNKS)\n",
                "    for a, b in pbar:\n",
                '        pbar.set_description(f"Chunk [{a}, {b}]")\n',
                "\n",
                "        # => INNER CHUNKS\n",
                "        for k in range(a, b):\n",
                "            # READ FILE\n",
                "            df = cudf.read_parquet(files[k])\n",
                '            df.ts = (df.ts / 1000).astype("int32")\n',
                '            df[["session", "aid"]] = df[["session", "aid"]].astype("int32")\n',
                '            df["type"] = df["type"].map(TYPE_LABELS).astype("int8")\n',
                "            gc.collect()\n",
                "            numba.cuda.current_context().deallocations.clear()\n",
                "\n",
                "            # NEW USERS IN LAST 2 WEEKS\n",
                '            df["mn"] = df.groupby("session").ts.transform("min")\n',
                "            df = df.loc[df.mn > 1662328791 - 60 * 60 * 24 * 21]\n",
                '            df = df.drop("mn", axis=1)\n',
                "            # print(files[k], df.shape )\n",
                "\n",
                '            df = df.sort_values(["session", "ts"], ascending=[True, True])\n',
                "\n",
                "            # USE TAIL OF SESSION\n",
                "            df = df.reset_index(drop=True)\n",
                '            df["n"] = df.groupby("session").cumcount()\n',
                "\n",
                "            # CREATE PAIRS\n",
                '            df = df.loc[df.n == 0].merge(df, on=["session"])\n',
                "            df = df.loc[df.aid_x != df.aid_y]\n",
                "\n",
                "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
                "            df = df.loc[(df.aid_x >= PART * SIZE) & (df.aid_x < (PART + 1) * SIZE)]\n",
                "\n",
                "            # ASSIGN WEIGHTS\n",
                '            df = df.sort_values(["session", "ts_y"], ascending=[True, True])\n',
                "            df = df[\n",
                '                ["session", "aid_x", "aid_y", "ts_x", "ts_y", "type_y"]\n',
                '            ].drop_duplicates(["session", "aid_x", "aid_y", "type_y"])\n',
                "\n",
                "            w = (1 / 2) ** ((df.ts_x - df.ts_y).abs() / 60 / 60)\n",
                '            df["wgt"] = w\n',
                "\n",
                '            df = df[["aid_x", "aid_y", "wgt"]]\n',
                '            df.wgt = df.wgt.astype("float32")\n',
                '            df = df.groupby(["aid_x", "aid_y"]).wgt.sum()\n',
                "\n",
                "            # COMBINE INNER CHUNKS\n",
                "            if k == a:\n",
                "                tmp2 = df\n",
                "            else:\n",
                "                tmp2 = tmp2.add(df, fill_value=0)\n",
                "\n",
                "        # COMBINE OUTER CHUNKS\n",
                "        if a == 0:\n",
                "            tmp = tmp2\n",
                "        else:\n",
                "            tmp = tmp.add(tmp2, fill_value=0)\n",
                "        del tmp2, df\n",
                "        gc.collect()\n",
                "\n",
                "    # CONVERT MATRIX TO DICTIONARY\n",
                "    tmp = tmp.reset_index()\n",
                '    tmp = tmp.sort_values(["aid_x", "wgt"], ascending=[True, False])\n',
                "\n",
                "    # SAVE TOP\n",
                "    tmp = tmp.reset_index(drop=True)\n",
                '    tmp["n"] = tmp.groupby("aid_x").aid_y.cumcount()\n',
                '    tmp = tmp.loc[tmp.n < 40].drop("n", axis=1)\n',
                "    matrices.append(tmp.to_pandas())\n",
                "\n",
                "    del tmp\n",
                "    gc.collect()\n",
                "    numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                'save_path = os.path.join(MATRIX_FOLDER, f"matrix_gpu-701_{MODE}.pqt")\n',
                'print(f"Saving matrix to {save_path}")\n',
                "pd.concat(matrices, ignore_index=True).to_parquet(save_path)\n",
                "\n",
                "del matrices\n",
                "gc.collect()\n",
                "numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {"cell_type": "markdown", "metadata": {}, "source": ["### cpu-90"]},
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ["DEBUG = False"],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def gen_pairs(df):\n",
                '    df = df.loc[(df["type"] == 1) | (df["type"] == 2)]\n',
                '    df = pd.merge(df, df, on="session")\n',
                '    pairs = df.query("abs(ts_x - ts_y) < 14 * 24 * 60 * 60 and aid_x != aid_y")[\n',
                '        ["session", "aid_x", "aid_y"]\n',
                '    ].drop_duplicates(["session", "aid_x", "aid_y"])\n',
                '    return pairs[["aid_x", "aid_y"]].values\n',
                "\n",
                "\n",
                "def gen_aid_pairs(all_pairs, files):\n",
                "    # all_pairs = defaultdict(lambda: Counter())\n",
                '    with tqdm(files, desc="Files") as prog:\n',
                "        with multiprocessing.Pool(20) as p:\n",
                "            for idx, chunk_file in enumerate(prog):\n",
                "                chunk = pd.read_parquet(chunk_file)  # .drop(columns=['type'])\n",
                '                chunk.ts = (chunk.ts / 1000).astype("int32")\n',
                '                chunk["type"] = chunk["type"].map(TYPE_LABELS).astype("int8")\n',
                "\n",
                "                pair_chunks = p.map(\n",
                "                    gen_pairs,\n",
                "                    np.array_split(chunk.head(100000000 if not DEBUG else 10000), 120),\n",
                "                )\n",
                "                for pairs in pair_chunks:\n",
                "                    for aid1, aid2 in pairs:\n",
                "                        all_pairs[aid1][aid2] += 1\n",
                "\n",
                "                if DEBUG and idx >= 2:\n",
                "                    break\n",
                "                del chunk, pair_chunks\n",
                "                gc.collect()\n",
                "    return all_pairs",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_pairs = gen_aid_pairs(defaultdict(lambda: Counter()), files)\n",
                "\n",
                "df = []\n",
                "for aid, cnt in tqdm(all_pairs.items()):\n",
                "    for aid2, freq in cnt.most_common(40):\n",
                '        df.append({"aid_x": aid, "aid_y": aid2, "wgt": freq})\n',
                "df = pd.DataFrame(df)\n",
                "\n",
                'save_path = os.path.join(MATRIX_FOLDER, f"matrix_cpu-90_{MODE}.pqt")\n',
                'print(f"Saving matrix to {save_path}")\n',
                "df.to_parquet(save_path)\n",
                "\n",
                "del df, all_pairs\n",
                "gc.collect()\n",
                "numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {"cell_type": "markdown", "metadata": {}, "source": ["### cpu-95"]},
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": ["DEBUG = False"],
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "def gen_pairs(df):\n",
                "    SAMPLING = 1\n",
                "\n",
                "    df = (\n",
                '        df.query("session % @SAMPLING == 0")\n',
                '        .groupby("session", as_index=False, sort=False)\n',
                "        .apply(lambda g: g.tail(30))\n",
                "        .reset_index(drop=True)\n",
                "    )\n",
                '    df = pd.merge(df, df, on="session")\n',
                '    pairs = df.query("aid_x != aid_y")[\n',
                '        ["session", "aid_x", "aid_y", "ts_x", "ts_y", "type_y"]\n',
                '    ].drop_duplicates(["session", "aid_x", "aid_y"])\n',
                '    return pairs[["aid_x", "aid_y", "ts_x", "ts_y", "type_y"]].values\n',
                "\n",
                "\n",
                "def gen_aid_pairs(all_pairs, files):\n",
                "    # all_pairs = defaultdict(lambda: Counter())\n",
                '    with tqdm(files, desc="Files") as prog:\n',
                "        with multiprocessing.Pool(20) as p:\n",
                "            for idx, chunk_file in enumerate(prog):\n",
                "                chunk = pd.read_parquet(chunk_file)\n",
                '                chunk.ts = (chunk.ts / 1000).astype("int32")\n',
                '                chunk["type"] = chunk["type"].map(TYPE_LABELS).astype("int8")\n',
                "\n",
                "                pair_chunks = p.map(\n",
                "                    gen_pairs,\n",
                "                    np.array_split(chunk.head(100000000 if not DEBUG else 10000), 120),\n",
                "                )\n",
                "                for pairs in pair_chunks:\n",
                "                    for aid1, aid2, ts1, ts2, typ in pairs:\n",
                "                        m = (1 / 2) ** (np.abs(ts2 - ts1) / 60 / 60)\n",
                "                        w = 1\n",
                "                        if (typ == 1) | (typ == 2):\n",
                "                            w = 4\n",
                "                        all_pairs[aid1][aid2] += w * m\n",
                "\n",
                "                if DEBUG and idx >= 2:\n",
                "                    break\n",
                "                del chunk, pair_chunks\n",
                "                gc.collect()\n",
                "    return all_pairs",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Files:  67%|   | 98/146 [4:03:42<2:54:34, 218.23s/it]"
                    ],
                }
            ],
            "source": [
                "all_pairs = gen_aid_pairs(defaultdict(lambda: Counter()), files)\n",
                "\n",
                "df = []\n",
                "for aid, cnt in tqdm(all_pairs.items()):\n",
                "    for aid2, freq in cnt.most_common(40):\n",
                '        df.append({"aid_x": aid, "aid_y": aid2, "wgt": freq})\n',
                "df = pd.DataFrame(df)\n",
                "\n",
                'save_path = os.path.join(MATRIX_FOLDER, f"matrix_cpu-95_{MODE}.pqt")\n',
                'print(f"Saving matrix to {save_path}")\n',
                "df.to_parquet(save_path)\n",
                "\n",
                "del df, all_pairs\n",
                "gc.collect()\n",
                "numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {"cell_type": "markdown", "metadata": {}, "source": ["### cpu-99"]},
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def gen_pairs(df):\n",
                '    df = pd.merge(df, df, on="session")\n',
                '    pairs = df.query("aid_x != aid_y")[\n',
                '        ["session", "aid_x", "aid_y", "ts_x", "ts_y"]\n',
                '    ].drop_duplicates(["session", "aid_x", "aid_y"])\n',
                '    return pairs[["aid_x", "aid_y", "ts_x", "ts_y"]].values\n',
                "\n",
                "\n",
                "def gen_aid_pairs(all_pairs, files):\n",
                "    # all_pairs = defaultdict(lambda: Counter())\n",
                '    with tqdm(files, desc="File") as prog:\n',
                "        with multiprocessing.Pool(20) as p:\n",
                "            for idx, chunk_file in enumerate(prog):\n",
                "                chunk = pd.read_parquet(chunk_file)\n",
                '                chunk.ts = (chunk.ts / 1000).astype("int32")\n',
                '                chunk["type"] = chunk["type"].map(TYPE_LABELS).astype("int8")\n',
                "\n",
                "                chunk = chunk.loc[chunk.ts > 1662328791 - 60 * 60 * 24 * 28]\n",
                '                chunk = chunk.loc[chunk["type"].isin([1, 2])]\n',
                "                pair_chunks = p.map(\n",
                "                    gen_pairs,\n",
                "                    np.array_split(chunk.head(100000000 if not DEBUG else 10000), 120),\n",
                "                )\n",
                "                for pairs in pair_chunks:\n",
                "                    for aid1, aid2, t1, t2 in pairs:\n",
                "                        w = (1 / 2) ** (np.abs(t2 - t1) / 60 / 60)\n",
                "                        all_pairs[aid1][aid2] += w\n",
                "\n",
                "                if DEBUG and idx >= 2:\n",
                "                    break\n",
                "                del chunk, pair_chunks\n",
                "                gc.collect()\n",
                "    return all_pairs",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_pairs = gen_aid_pairs(defaultdict(lambda: Counter()), files)\n",
                "\n",
                "df = []\n",
                "for aid, cnt in tqdm(all_pairs.items()):\n",
                "    for aid2, freq in cnt.most_common(40):\n",
                '        df.append({"aid_x": aid, "aid_y": aid2, "wgt": freq})\n',
                "df = pd.DataFrame(df)\n",
                "\n",
                'save_path = os.path.join(MATRIX_FOLDER, f"matrix_cpu-99_{MODE}.pqt")\n',
                'print(f"Saving matrix to {save_path}")\n',
                "df.to_parquet(save_path)\n",
                "\n",
                "del df, all_pairs\n",
                "gc.collect()\n",
                "numba.cuda.current_context().deallocations.clear()",
            ],
        },
        {"cell_type": "markdown", "metadata": {}, "source": ["Done !"]},
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3",
        },
        "language_info": {
            "codemirror_mode": {"name": "ipython", "version": 3},
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10",
        },
    },
    "nbformat": 4,
    "nbformat_minor": 4,
}
